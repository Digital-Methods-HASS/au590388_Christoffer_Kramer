---
title: "final Project"
author: "Christoffer M. Kramer"
date: "26/11/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidytext)
library(dplyr)
library(ggplot2)
library(tidyr)
library(ggwordcloud)
library(wordcloud)
library(reshape2)
library(qdap)
library(magrittr)
library(rvest) 
library(dplyr) 
library(tidyr)
library(zoo)
library(stringr)
library(naniar)
library(lubridate)
library(wordcloud2)
library(tm)
```
#NOTER MANGLER
DU SKAL FJERNE TALVÆRDIER (MANGE HAR KOMMA; HVILKET SKABER PROBLEMER). Hav et objekt, der er blevet tokeniseret, som kan bruges efterfølgende vha. tidyverse. De relevante objekter i de relevante kapitler, dette er bedre.  
Vælg nolge enkelte værktøjer og fokuser på dem.
Mangler -ngram (sentiment)
Mangler - ngram (netværk)

## Web scraping
```{r}
# Scrape Debate function --------------------------------------------------
scrape_debates <- function(website) {
  p_html <-  read_html(website) %>%
    html_nodes("p") %>%
    html_text()

  vect_p_html <- c(p_html) #Save the output in a vector.
}


# Get and store links to debates ---------------------------------------------------
link_html <- read_html("https://www.debates.org/voter-education/debate-transcripts/") %>%
  html_nodes("blockquote") %>%
  html_children() %>%
  html_nodes("a")  %>%
  html_attr("href")



vect_link <- c(link_html) #save the output in a vector
vect_link #Check output

#Clean messy links
vect_link[1] <- "/voter-education/debate-transcripts/september-29-2020-debate-transcript/"
vect_link[2] <- "/voter-education/debate-transcripts/vice-presidential-debate-at-the-university-of-utah-in-salt-lake-city-utah/"
vect_link[3] <- "/voter-education/debate-transcripts/october-22-2020-debate-transcript/"


# Loop through the links and store the content ----------------------------
debate_names <-NULL
all_debates <- tibble()

for (link in vect_link[!is.na(vect_link)]) {
  name <- str_extract(link, "[A-Za-z]+-\\d+-\\d+")

 if(is.na(name)) {

  name <- str_extract(link, ".+")

 }

  debate_names <- append(debate_names, name)

  website <- paste0("https://www.debates.org/", link)
  debate <- scrape_debates(website)
  debate <- tibble(line = 1:length(debate), text = debate, date = name)
  all_debates <- bind_rows(all_debates, debate)
}
```


## Cleaning
```{r}


#CHANGE THE REGEX FOR CATCHING NAMES (I DONT WANT MR. OR MS.)!!

# Make list of candidates a tibble ------------------------------------------------
candidates <- read.csv(file = "data/candidates_since_1960.csv", sep = ";")
candidates <- tibble(candidates) %>% 
  mutate(last_name = toupper(last_name))


# Save transcripts as csv and create a tibble --------------------------------------------------------------
write.csv(all_debates, "data/all_debates.csv", row.names=FALSE)
all_debates <- read.csv("data/all_debates.csv")
all_debates <- tibble(all_debates)


# Clean names in debate column ----------------------------------------------
#Functions that cleans names by replacing an existing string with a new string
clean_names <- function(dataset, old_pattern, new_replacement) {
  mutate_if(dataset,
            is.character,
            str_replace_all, pattern = old_pattern, replacement = new_replacement)
}

#Find the wrong names
wrong_names <- debate_names[grep("[A-Za-z]+-\\d+-\\d+", debate_names, invert = TRUE)]

#Remove translations page from list of names and the dataset
debate_names <- debate_names[!(debate_names == "/voter-education/debate-transcripts/2000-debate-transcripts-translations/")]
all_debates <- all_debates[!(all_debates$date == "/voter-education/debate-transcripts/2000-debate-transcripts-translations/"),]

#Make a list of correct names
right_names <- c("october-7-2020", "september-26-2008", "october-2-2008", "september-26-2008")   

i <- 0 #Index
#Loop through every wrong name and replace it with a name from the vector "right_names" in the dataset and the vector with names
for (name in wrong_names) {
  i <- i+1  
  all_debates <- clean_names(all_debates, old_pattern = name, new_replacement = right_names[i])
  debate_names[name] <- right_names[i] 
}


# Make "date" a proper date with different columns for day, month and year ------------------------------------------------
all_debates <- all_debates %>% 
  mutate(date = mdy(date)) %>% 
  mutate(day = day(date),
         month = month(date),
         year = year(date)
  )

# Find all names and save as a tibble --------------------------------------------------------------------------------
last_name <- str_extract(all_debates$text, "^[A-Za-z]+:|^M[RS]\\..+:") %>% 
  str_extract("[A-Z]+:") %>% 
  str_extract("[A-Z]+")
last_name <- tibble(last_name)


# bind column to all debates and fill out every cell in last_name, make all last_names uppercase ------------------------------------------------------------------------------------------
all_debates <- cbind(all_debates, last_name)
all_debates <- na.locf(all_debates)

all_debates %>% 
  mutate(last_name = toupper(last_name))

#Combine the tibble with candidates and the debates by last_name and year ---------------------------------------------
all_debates <- left_join(all_debates, candidates, by = c("last_name" = "last_name", "year" = "year"))
all_debates[is.na(all_debates)] <- "not_a_candidate" #fill na's

# Remove the names from the text --------------------------------------------------------------------------------------
 all_debates <- all_debates %>%
   mutate(text = str_remove(text, "^[A-Z]+:|^M[RS]\\..+:"))

# reorder columns ----------------------------------------------------------------------------------------------------
all_debates <- all_debates %>% 
  relocate(last_name, .before = text)
all_debates <- all_debates %>% 
  relocate(first_name, .before = last_name)


```

```{r cars}
my_stop_words <- tibble(word = c("uh", "uhh"))

debate_words <- all_debates %>% 
  unnest_tokens(word, text) %>% 
  anti_join(my_stop_words) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(year, party, word, sort = TRUE)

debate_words_party <- all_debates %>% 
  unnest_tokens(word, text) %>% 
  anti_join(my_stop_words) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, word, sort = TRUE) %>% 
  mutate(word = gsub("\u2019", "'", word)) %>%  
  anti_join(stop_words)

# Stop word filtering -------------------------------------------
debates_stop_words_removed <- debate_words %>% 
  mutate(word = gsub("\u2019", "'", word)) %>%  
  anti_join(stop_words)


test <- debates_stop_words_removed %>% 
  group_by(word) %>% 
  summarise(word_n = n())
  view(debate_words_party)
#Get a list of all years for plotting and loops
# all_years <- map_dbl((debates_stop_words_removed %>% 
#   select(year) %>% 
#   unique() %>% 
#   arrange(desc(year))))
# 
# map_dbl()
# all_years
```

## Including Plots

You can also embed plots, for example:
### Democrats
```{r pressure, echo=FALSE}
debates_stop_words_removed %>% 
    filter(party == "D") %>% 
    group_by(year) %>% 
    top_n(20) %>% 
    ungroup %>% 
    ggplot(aes(label = word, size = n)) +
    geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal() +
    facet_wrap(~year, ncol = 2, scales = "free")
ggsave("word_cloud_dems.pdf", width = 65, height = 35, units = "cm")
```


```{r}
debate_words_party %>% 
    filter(party == "D") %>% 
    top_n(20) %>% 
    ggplot(aes(label = word, size = n)) +
    geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal()

ggsave("word_cloud_dems.pdf", width = 65, height = 35, units = "cm")
```



### Republicans
```{r, echo=FALSE}
debates_stop_words_removed %>% 
  filter(party != "R") %>%
  group_by(year, party) %>% 
  top_n(20) %>% 
  ungroup %>% 
  ggplot(aes(label = word, size = n)) +
  geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
  #scale_size_area(max_size = 12) +
  scale_color_gradientn(colors = c("darkgreen","blue","red")) +
  theme_minimal() +
  facet_wrap(~year, ncol = 3, scales = "free")

ggsave("word_cloud_rep.pdf", width = 65, height = 35, units = "cm")
```



```{r}
debate_words_party %>% 
    filter(party == "R") %>% 
    top_n(20) %>% 
    ggplot(aes(label = word, size = n)) +
    geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal()
```


### Both Parties

```{r}
dems <- debates_stop_words_removed %>% 
  filter(party == "D")


reps <- debates_stop_words_removed %>% 
  filter(party == "R")


shared_words <- semi_join(reps, dems, by = c("word" = "word"))

shared_words %>% 
    top_n(20) %>% 
    ggplot(aes(label = word, size = n)) +
    geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal()
```

```{r}

shared_words_all_years <- semi_join(reps, dems, by = c("word" = "word"))

debates_stop_words_removed %>% 
    group_by(year) %>% 
    top_n(20) %>% 
    ungroup %>% 
    ggplot(aes(label = word, size = n)) +
    geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal() +
    facet_wrap(~year, ncol = 2, scales = "free")
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

## TF_IDF all debates
```{r}
total_words_all <- all_debates %>% 
  unnest_tokens(word, text) %>% 
  count(year, word, sort = TRUE) %>% 
  group_by(year) %>% 
  summarise(total = sum(n))

words_count <- all_debates %>% 
  unnest_tokens(word, text) %>% 
  count(year, word, sort = TRUE) %>% 
  left_join(total_words_all, by = "year")

words_count


words_tf_idf <- words_count %>% 
  bind_tf_idf(word, year, n) 

words_tf_idf
```

### Plot all_debates
```{r}
words_tf_idf %>% 
  arrange(desc(tf_idf)) %>% 
  group_by(year) %>% 
  top_n(20) %>% 
    ungroup %>% 
    ggplot(aes(label = word, size = tf_idf)) +
    geom_text_wordcloud_area(aes(color = tf_idf), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal() +
    facet_wrap(~year, ncol = 3, scales = "free")

ggsave("word_cloud_tf_idf.pdf", width = 65, height = 35, units = "cm")
```

### TF R and D

```{r}
total_words_all <- all_debates %>% 
  filter(party != "I") %>% 
  filter(party != "not_a_candidate") %>% 
  unnest_tokens(word, text) %>% 
  count(party, word, sort = TRUE) %>% 
  group_by(party) %>% 
  summarise(total = sum(n))

words_count <- all_debates %>% 
  filter(party != "I") %>% 
  filter(party != "not_a_candidate") %>%  
  unnest_tokens(word, text) %>% 
  count(party, word, sort = TRUE) %>% 
  left_join(total_words_all, by = "party")



words_tf_idf <- words_count %>% 
  bind_tf_idf(word, party, n) 

words_tf_idf %>% 
  arrange(desc(tf_idf)) %>% 
  group_by(party) %>% 
  top_n(50) %>% 
    ungroup %>% 
    ggplot(aes(label = word, size = tf_idf)) +
    geom_text_wordcloud_area(aes(color = tf_idf), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal() +
    facet_wrap(~party, ncol = 2, scales = "free")




```

### TF All
```{r}
total_words_all <- all_debates %>% 
  unnest_tokens(word, text) %>% 
  count(party, word, sort = TRUE) %>% 
  group_by(party) %>% 
  summarise(total = sum(n))

words_count <- all_debates %>% 
  unnest_tokens(word, text) %>% 
  count(party, word, sort = TRUE) %>% 
  left_join(total_words_all, by = "party")



words_tf_idf <- words_count %>% 
  bind_tf_idf(word, party, n) 

words_tf_idf %>% 
  arrange(desc(tf_idf)) %>% 
  group_by(party) %>% 
  top_n(50) %>% 
    ungroup %>% 
    ggplot(aes(label = word, size = tf_idf)) +
    geom_text_wordcloud_area(aes(color = tf_idf), shape = "diamond") +
    scale_size_area(max_size = 12) +
    scale_color_gradientn(colors = c("darkgreen","blue","red")) +
    theme_minimal() +
    facet_wrap(~party, ncol = 2, scales = "free")

```

## Sentiment analysis
### Afinn

```{r}
dems <- all_debates %>% 
  filter(party == "D") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, word, sort = TRUE)
  
reps <- all_debates %>% 
  filter(party == "R") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, word, sort = TRUE)

# Affin Democrats and Republicans -----------------------------------------
affin_R <- reps %>% 
  inner_join(get_sentiments("afinn"))

affin_D <- dems %>% 
  inner_join(get_sentiments("afinn"))
```


```{r}
# Plot Afinn --------------------------------------------------------------
affin_R_plot <- affin_R %>% 
  count(value) %>% 
  ggplot(aes(x = value, y = n)) + 
  geom_col()
affin_R_plot
```


```{r}
affin_D_plot <- affin_D %>% 
  count(value) %>% 
  ggplot(aes(x = value, y = n)) + 
  geom_col()
affin_D_plot
```

###Afinn all years Democrats
```{r}
dems <- all_debates %>% 
  filter(party == "D") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, year, word, sort = TRUE) %>% 
  inner_join(get_sentiments("afinn"))
  

affin_D_plot <- dems %>% 
  group_by(year) %>% 
  count(value) %>% 
  ggplot(aes(x = value, y = n)) + 
  geom_col() +
  facet_wrap(~year, ncol = 3, scales = "free")
affin_D_plot




```

###Afinn all years republicans
```{r}
reps <- all_debates %>% 
  filter(party == "R") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, year, word, sort = TRUE) %>% 
  inner_join(get_sentiments("afinn"))

affin_R_plot <- dems %>% 
  group_by(year) %>% 
  count(value) %>% 
  ggplot(aes(x = value, y = n)) + 
  geom_col() +
  facet_wrap(~year, ncol = 3, scales = "free")
affin_D_plot
```

### NRC
```{r}
# NRC ---------------------------------------------------------------------
nrc_R <- dems %>% 
  inner_join(get_sentiments("nrc"))

nrc_D <- reps %>% 
  inner_join(get_sentiments("nrc"))

# Plot NRC ----------------------------------------------------------------
ggplot(data = nrc_R, aes(x = sentiment, y = n)) +
  geom_col()

ggplot(data = nrc_D, aes(x = sentiment, y = n)) +
  geom_col()
```


### NRC all years dems
```{r}
dems <- all_debates %>% 
  filter(party == "D") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, year, word, sort = TRUE) %>% 
  inner_join(get_sentiments("nrc"))

dems %>% 
  group_by(year) %>% 
  count(sentiment) %>% 
  ggplot(aes(x = sentiment, y = n)) + 
  geom_col() +
  facet_wrap(~year, ncol = 3, scales = "free")

```


### NRC all years reps
```{r}
reps <- all_debates %>% 
  filter(party == "R") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, year, word, sort = TRUE) %>% 
  inner_join(get_sentiments("nrc"))

reps %>% 
  group_by(year) %>% 
  count(sentiment) %>% 
  ggplot(aes(x = sentiment, y = n)) + 
  geom_col() +
  facet_wrap(~year, ncol = 3, scales = "free")

```



###BING

```{r}
# bing --------------------------------------------------------------------
bing_R <- reps %>% 
  inner_join(get_sentiments("bing"))

bing_D <- dems%>% 
  inner_join(get_sentiments("bing"))

# Plot bing ---------------------------------------------------------------)
ggplot(data = bing_R, aes(x = sentiment, y = n)) +
  geom_col()

ggplot(data = bing_D, aes(x = sentiment, y = n)) +
  geom_col()


```
### BING all years dems
```{r}
dems <- all_debates %>% 
  filter(party == "D") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, year, word, sort = TRUE) %>% 
  inner_join(get_sentiments("bing"))

dems %>%
  group_by(year) %>% 
  count(sentiment) %>% 
  ggplot(aes(x = sentiment, y = n)) + 
  geom_col() +
  facet_wrap(~year, ncol = 3, scales = "free")

```


### BING all years reps
```{r}
reps <- all_debates %>% 
  filter(party == "R") %>% 
  unnest_tokens(word, text) %>% 
  filter(is.na(as.numeric(word))) %>%
  count(party, year, word, sort = TRUE) %>% 
  inner_join(get_sentiments("bing"))

reps %>%
  group_by(year) %>% 
  count(sentiment) %>% 
  ggplot(aes(x = sentiment, y = n)) + 
  geom_col() +
  facet_wrap(~year, ncol = 3, scales = "free")
```



## NETWORKS



## Ekstra shit
```{r}
# debates_only_R_and_D <- debates_stop_words_removed %>%
#     filter(party != "not_a_candidate") %>%
#     filter(party != "I" ) 
# 
# # print(all_years)
# # for (i in seq_along(all_years)) {
# #   print(i)
# # # data <-  debates_only_R_and_D %>%
# # #     filter(year == i) %>%
# # #    acast(word ~ party, fun.aggregate = sum, value.var = "n", fill = 0)
# # # print(data)
# # }
# 
# test <- 
#   debates_only_R_and_D %>% 
#   split(.$year)
# 
# # test %>% 
# #   walk(print)
# # 
# # test
# # walk(all_years, debates_only_R_and_D %>% 
# #     acast(word ~ party, fun.aggregate = sum, value.var = "n", fill = 0) %>% 
# #     comparison.cloud(colors = c("blue", "red"),
# #                      max.words = 20))
# # 
# 
# # map()
# test1 <- all_debates$year %>% unique()
# test1 <- c(test1)
# test1 <- all_debates[["year"]]
# test1 <- test1 %>%  unique()
# test1 <- c(test1)
# test1
# length(test1)
# 
# for (i in test) {
# label_year <- i$year %>% unique()
#  i %>%
#  acast(word ~ party, value.var = "n", fill = 0) %>%
#  comparison.cloud(colors = c("blue", "red"),
#  max.words = 20,
#  scale = c(2,0.25),
#  title.size = 1,
#  random.order = TRUE,
#  match.colors = TRUE)
# 
# #ggsave(paste(j,"word_cloud.png", sep = "_"), width = 65, height = 35, units = "cm")
# }
# 
#  testing <- i %>%
#     acast(word ~ party, fun.aggregate = sum, value.var = "n", fill = 0)
#   view(testing)
#   
#   
#   for(i in test1){
#     
#     debates_stop_words_removed %>% 
#       filter(part == "D")
#     
#    acast(word ~ party, fun.aggregate = sum, value.var = "n", fill = 0) %>%
#    comparison.cloud(colors = c("blue", "red"),
#    max.words = 50,
#    scale = "c(2,0.25)",
#    title.size = 1,
#    random.order = FALSE,
#    match.colors = TRUE)
#     }
# 
#  ggsave("word_cloud_test.pdf", width = 65, height = 35, units = "cm")
# all_years <- all_debates %>% 
#   filter(party == "R")
# 
# test <- all_debates %>% 
#   unnest_tokens(word, text) %>% 
#   anti_join(my_stop_words) %>% 
#   filter(is.na(as.numeric(word))) %>%
#   count(word, sort = TRUE)
# 
# 
# test <- test %>% 
#   mutate(word = gsub("\u2019", "'", word)) %>%  
#   anti_join(stop_words)
# 
# 
# # test <- debates_only_R_and_D %>% acast(word ~ n, value.var = "n", fill = 0) 
# # view(test)
# wordcloud2(test)
# view(data)
```

